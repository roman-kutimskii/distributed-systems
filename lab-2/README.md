# PA2. Знакомство с Nginx

**Цель**: научиться масштабировать веб-приложение с помощью сервера Nginx

## Задание

*Работа делается на основе задания PA1.*

**Масштабируемость** — способность распределённой системы эффективно справляться с ростом числа пользователей и/или числа обслуживаемых ресурсов без увеличения административной нагрузки на её обслуживание.

В данной работе мы применим относительно простой и быстрый способ масштабирования — добавление новых экземпляров приложения. Такой способ масштабирования называется горизонтальным.

- В реальных условиях экземпляры веб-приложения обычно запускаются на разных физических машинах.
- Нам будет достаточно запускать все экземпляры на одном компьютере в виде отдельных процессов.
- При запуске процессов на одном компьютере необходимо следить, чтобы каждому процессу был назначен свободный порт
- Процесс не запустится, если назначенный ему порт уже занят другим процессом.

## Порядок выполнения

Для начала запустите два процесса веб-приложения *Valuator* на портах 5001 и 5002.

Для запуска ASP.Net Core приложения с указанием порта можно воспользоваться параметром `--urls "http://0.0.0.0:5001"`, что означает «слушать порт на всех сетевых интерфейсах»

``` bash
dotnet run --urls "http://0.0.0.0:5001"
```

После запуска проверьте работоспособность каждого экземпляра приложения, обратившись напрямую по номеру его порта, например  http://localhost:5001

Пользователь будет обращаться к приложению через сервер-посредник, который должен иметь постоянный адрес, а посредник будет ретранслировать пользовательские запросы на запущенные экземпляры приложения.

- такой сервер-посредник называется *обратный прокси* (reverse proxy)
- мы будем использовать nginx — популярный и гибко настраиваемый HTTP-сервер
- мы применим nginx не только как обратный прокси, но и как *балансировщик нагрузки* (load balancer).

OpenSource версия Nginx доступна по адресу: http://nginx.org/ru/

В рамках задания необходимо:

1. Настроить Nginx в качестве прокси-сервера
2. Автоматизировать запуск/останов системы

### Настройка Nginx в качестве прокси-сервера

>Вы можете использовать либо не использовать docker и docker-compose на своё усмотрение.

На основании прилагаемого файла конфигурации [nginx/conf/nginx.conf](nginx/conf/nginx.conf) необходимо настроить прокси-сервер на Nginx.

- Пользователь должен обращаться к приложению по адресу http://localhost:8080/, на котором запущен nginx-сервер
- Все пользовательские запросы должны проксироваться для обработки к процессам, запущенным на портах 5001 и 5002.

После успешной настройки прокси-сервера попробуйте провести эксперименты с остановом (отказом) экземпляров веб-приложения и добавлением новых экземпляров на других портах (5003, 5004 и т.д.).

Поэкспериментируйте с разными методами балансировки нагрузки. Описание методов можно найти здесь:
http://nginx.org/en/docs/http/load_balancing.html#nginx_load_balancing_methods

### Автоматизация запуска / останова системы

>Вы можете использовать либо не использовать docker и docker-compose на своё усмотрение. 

С увеличением числа компонентов возрастает риск человеческой ошибки при её обслуживании. Уменьшить человеческий фактор помогают скрипты, которые автоматизируют рутинные процессы.

В рамках данного задания необходимо автоматизировать этапы запуска и останова компонентов нашего приложения.

Необходимо разработать и разместить в директории *scripts* следующие файлы:

1. `start.(cmd|ps1|sh)` - скрипт запуска компонентов (процессов веб-приложения и прокси-сервера Nginx)
2. `stop.(cmd|ps1|sh)` - скрипт останова компонентов (процессов веб-приложения и прокси-сервера Nginx)

## Ссылки

1. [Nginx](http://nginx.org/ru/)
2. [Using nginx as HTTP load balancer](http://nginx.org/en/docs/http/load_balancing.html)
3. [Запуск nginx в docker-compose](https://atdd.ru/nginx/nginx-in-docker-compose.html)
